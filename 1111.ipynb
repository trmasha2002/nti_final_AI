{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GdYMzXkKPoZ2"
   },
   "source": [
    "Импортируем нужные библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B1Exn-ryPoZ5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-oBs3DlzPoZ_"
   },
   "source": [
    "Распакуйте архив с данными в папку,где находится этот jupyter notebook (baseline.ipynb). У вас будет папка data,  содержащая необходимые файлы. \n",
    "\n",
    "Ваша задача предсказать вероятность совершения покупки Клиентом в определенных 8 категориях в следующие 7 дней, чтобы под них Банк смог направить релевантный контент (подборки). Для подготовки предсказания у вас есть данные по транзакциям 50 000 Клиентов в течение года, из которых 25 000 – в обучающей выборке и 25 000 – в тестовой. Ваша задача для тестовой выборки рассчитать для каждой из целевой категории вероятность совершения покупки в ней на следующей неделе.\n",
    "\n",
    "Данные по транзакциям находятся в файле **transactions_train.csv**. Информация о покупках по категориям для исследуемой недели находится в файле **train_target.csv**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rGqNGGpDPoaB"
   },
   "source": [
    "Считаем данные по транзакциям и правильные ответы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k456Mi1tPoaC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transactions_train = pd.read_csv('transactions_train.csv')\n",
    "train_target = pd.read_csv('train_target.csv')\n",
    "transactions_test = pd.read_csv('transactions_test.csv')\n",
    "test_id = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_amount_features(transactions, name):\n",
    "    amount_cat = transactions.groupby(['client_dk','small_group']).sum()['amount']\n",
    "    amount_cat = amount_cat.reset_index().pivot(index='client_dk', \\\n",
    "                                                      columns='small_group',values='amount')\n",
    "    amount_cat = amount_cat.fillna(0)\n",
    "    amount_cat.columns = [name + str(i) for i in amount_cat.columns]\n",
    "    return amount_cat\n",
    "\n",
    "def get_count_features(transactions, name):\n",
    "    counter_df = transactions.groupby(['client_dk','small_group'])['amount'].count()\n",
    "    cat_counts = counter_df.reset_index().pivot(index='client_dk', \\\n",
    "                                                      columns='small_group',values='amount')\n",
    "    cat_counts = cat_counts.fillna(0)\n",
    "    cat_counts.columns = [name + str(i) for i in cat_counts.columns]\n",
    "    return cat_counts\n",
    "\n",
    "\n",
    "def get_features(transactions, target):\n",
    "    agg_features = transactions.groupby('client_dk')['amount'].agg(['mean','max','min','std','sum','count']).reset_index()\n",
    "    \n",
    "    count_cat = get_count_features(transactions, 'cat_count_')\n",
    "    amount_cat = get_amount_features(transactions, 'cat_spend_')\n",
    "    \n",
    "    count_cat_norm = get_count_features(transactions[(transactions.amount >= 100) & (transactions.amount <= 1500)], 'cat_count_norm_')\n",
    "    amount_cat_norm = get_amount_features(transactions[(transactions.amount >= 100) & (transactions.amount <= 1500)], 'cat_spend_norm_')\n",
    "    \n",
    "    amount_cat_last_week = get_amount_features(transactions[transactions.trans_date > 380], 'cat_spend_last_week_')\n",
    "    count_cat_last_week = get_count_features(transactions[transactions.trans_date > 380], 'cat_count_last_week_')  \n",
    "    \n",
    "    amount_cat_last_3days = get_amount_features(transactions[transactions.trans_date > 384], 'cat_spend_last_3days_')\n",
    "    count_cat_last_3days = get_count_features(transactions[transactions.trans_date > 384], 'cat_count_last_3days_')  \n",
    "    \n",
    "    amount_cat_last_2weeks = get_amount_features(transactions[transactions.trans_date > 373], 'cat_spend_last_2weeks_')\n",
    "    count_cat_last_2weeks = get_count_features(transactions[transactions.trans_date > 373], 'cat_count_last_2weeks_')   \n",
    "    \n",
    "    amount_cat_last_month = get_amount_features(transactions[transactions.trans_date > 357], 'cat_spend_last_month_')\n",
    "    count_cat_last_month = get_count_features(transactions[transactions.trans_date > 357], 'cat_count_last_month_')    \n",
    "    \n",
    "    amount_cat_sport_peak = get_amount_features(transactions[(transactions.trans_date >= 283) & (transactions.trans_date <= 300)], 'cat_spend_sport_peak_')\n",
    "    count_cat_sport_peak = get_count_features(transactions[(transactions.trans_date >= 283) & (transactions.trans_date <= 300)], 'cat_count_sport_peak_')    \n",
    "    \n",
    "    amount_cat_flower_peak = get_amount_features(transactions[(transactions.trans_date >= 126) & (transactions.trans_date <= 127)], 'cat_spend_flower_peak_')\n",
    "    count_cat_flower_peak = get_count_features(transactions[(transactions.trans_date >= 126) & (transactions.trans_date <= 127)], 'cat_count_flower_peak_')    \n",
    "    \n",
    "    amount_cat_week_year_ago = get_amount_features(transactions[(transactions.trans_date >= 333) & (transactions.trans_date <= 339)], 'cat_spend_week_year_ago_')\n",
    "    count_cat_week_year_ago = get_count_features(transactions[(transactions.trans_date >= 333) & (transactions.trans_date <= 339)], 'cat_count_week_year_ago_')   \n",
    "    \n",
    "    out = pd.merge(target, agg_features, on='client_dk', how='outer')\n",
    "    out = pd.merge(out, count_cat.reset_index(), on='client_dk', how='outer')\n",
    "    out = pd.merge(out, amount_cat.reset_index(), on='client_dk', how='outer')\n",
    "    out = pd.merge(out, count_cat_last_week.reset_index(), on='client_dk', how='outer')\n",
    "    out = pd.merge(out, amount_cat_last_week.reset_index(), on='client_dk', how='outer')\n",
    "    out = pd.merge(out, count_cat_last_3days.reset_index(), on='client_dk', how='outer')\n",
    "    out = pd.merge(out, amount_cat_last_3days.reset_index(), on='client_dk', how='outer')\n",
    "    out = pd.merge(out, count_cat_last_2weeks.reset_index(), on='client_dk', how='outer')\n",
    "    out = pd.merge(out, amount_cat_last_2weeks.reset_index(), on='client_dk', how='outer')\n",
    "    out = pd.merge(out, count_cat_last_month.reset_index(), on='client_dk', how='outer')\n",
    "    out = pd.merge(out, amount_cat_last_month.reset_index(), on='client_dk', how='outer')\n",
    "    out = pd.merge(out, count_cat_sport_peak.reset_index(), on='client_dk', how='outer')\n",
    "    out = pd.merge(out, amount_cat_sport_peak.reset_index(), on='client_dk', how='outer')\n",
    "    out = pd.merge(out, count_cat_flower_peak.reset_index(), on='client_dk', how='outer')\n",
    "    out = pd.merge(out, amount_cat_flower_peak.reset_index(), on='client_dk', how='outer')\n",
    "    out = pd.merge(out, count_cat_week_year_ago.reset_index(), on='client_dk', how='outer')\n",
    "    out = pd.merge(out, amount_cat_week_year_ago.reset_index(), on='client_dk', how='outer')\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NXxlvrTZPoap"
   },
   "outputs": [],
   "source": [
    "train = get_features(transactions_train, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_features(transactions_test, test_id[['client_dk']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_features = list(set(test.columns).intersection(set(train.columns)))\n",
    "cf = []\n",
    "for i in common_features:\n",
    "    if \"cat\" in i:\n",
    "        if \"_27\" in i or \"_32\" in i or \"_41\" in i or \"_45\" in i or \"_18\" in i  or \"_11\" in i or \"_67\" in i or \"_73\" in i or \"_81\" in i or \"_88\" in i or (\"flower\" in i and \"_37\" in i):\n",
    "            cf.append(i)\n",
    "    else:\n",
    "        cf.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_features = cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9XojgfYmPoa7"
   },
   "outputs": [],
   "source": [
    "X_train = train[common_features]\n",
    "X_test = test[common_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L6hPvLx9Poa8"
   },
   "source": [
    "В этом бэйзлайне мы будем использовать простой подход - предсказывать покупки в каждой категории независимо. То есть в цикле модель обучается на отдельную категорию как на зависимую переменную, и пытается предсказать наличие покупки в этой определенной категории для теста. В итоге у нас получается 8 задач бинарной классификации.\n",
    "\n",
    "**Важно**: Такой подход не претендует на звание лучшего, вы вольны придумать свой алгоритм решения, который, вполне вероятно, окажется лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': 1000,\n",
    "    'depth': 6,\n",
    "    'random_state':42,\n",
    "    'learning_rate': 0.027,\n",
    "    'eval_metric': 'AUC',\n",
    "    'loss_function': 'MultiClass',\n",
    "    'verbose': 1000, \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ydHIGxOFPoa9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#В словарь будем записывать предсказания модели\n",
    "results_tree = {}\n",
    "main_result = [] \n",
    "#Цикл со второго элемента, потому что первой колонкой идет идентификатор клиента \n",
    "for q in train_target.columns[1:]:\n",
    "    print('train product '+str(q))\n",
    "    curr_target_train = train_target.loc[:,q]\n",
    "    model = CatBoostClassifier(**params)\n",
    "    #model = DecisionTreeClassifier(random_state=42)\n",
    "    model.fit(X_train.fillna(0).values,curr_target_train.values)\n",
    "    main_result.append(model.get_evals_result())\n",
    "    #Сделаем предсказание\n",
    "    pred = model.predict_proba(X_test.fillna(0).values)[:,1]\n",
    "    results_tree[q] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C1oAvd1kPoa-"
   },
   "source": [
    "Такое решение дает на публичном лидерборде качество 0.6023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "khm5b0kAPoa-"
   },
   "source": [
    "### Подготовим файл для отправки в систему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hun-NrfzPoa-"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data=np.zeros((25000,8)),columns=train_target.columns[1:],index=test_id['client_dk'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W4bVC2NOPoa_"
   },
   "outputs": [],
   "source": [
    "for q in results_tree:\n",
    "    submission[q] = results_tree[q]\n",
    "submission.columns = ['cat_27','cat_32','cat_41','cat_45','cat_67','cat_73','cat_81','cat_88']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GWS7f9xXPobB"
   },
   "outputs": [],
   "source": [
    "submission.index.name = 'client_dk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oEwii6RGPobC"
   },
   "source": [
    "Сохраняем прогноз на диск в папку submissions. Имя прогноза соответсвует дате и времени его создания, закодированными с помощью timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vTBoZUHBPobC"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "current_timestamp = int(time.time())\n",
    "submission_path = 'submissions/{}.csv'.format(current_timestamp)\n",
    "\n",
    "if not os.path.exists('submissions'):\n",
    "    os.makedirs('submissions')\n",
    "\n",
    "print(submission_path)\n",
    "submission.to_csv(submission_path, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9wdMNIdKPobD"
   },
   "source": [
    "Теперь все готово! Можно отправлять решение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(main_result[0]['learn']['MultiClass']) #27.Спортивные мероприятия - синий\n",
    "plt.plot(main_result[1]['learn']['MultiClass']) # 32. Театр - оранжевый\n",
    "plt.plot(main_result[2]['learn']['MultiClass']) # 41.Ночной клуб - зеленый\n",
    "plt.plot(main_result[3]['learn']['MultiClass']) # 45.Кинотеатры - красный\n",
    "plt.plot(main_result[4]['learn']['MultiClass']) # 67.Доставка еды - фиолетовый светлый\n",
    "plt.plot(main_result[5]['learn']['MultiClass']) # 73.Выставки - фиолетовый темный\n",
    "plt.plot(main_result[6]['learn']['MultiClass']) # 81.Билеты на спортивные мероприятия - розовый\n",
    "plt.plot(main_result[7]['learn']['MultiClass']) # 88.Цирк - черный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(main_result[1]['learn']['MultiClass']) #32.Театр\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(main_result[2]['learn']['MultiClass']) #33. Ночные клубы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "baseline_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
